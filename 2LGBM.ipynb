{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea38c91-3c58-48f9-b6ab-ab8a9bf6bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy matplotlib seaborn scikit-learn lightgbm shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fbf08c-bd2a-43aa-ac06-18cd94fee3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinesh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1) Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8e4eec-3cb6-42b7-b63a-727b7651e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Import CSV data\n",
    "\n",
    "train = pd.read_csv('C:\\\\Users\\\\Dinesh\\\\Documents\\\\Python Scripts\\\\burnout-datathon-ieeecsmuj\\\\train.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\Dinesh\\\\Documents\\\\Python Scripts\\\\burnout-datathon-ieeecsmuj\\\\test.csv')\n",
    "val = pd.read_csv('C:\\\\Users\\\\Dinesh\\\\Documents\\\\Python Scripts\\\\burnout-datathon-ieeecsmuj\\\\val.csv')\n",
    "sample_submission = pd.read_csv('C:\\\\Users\\\\Dinesh\\\\Documents\\\\Python Scripts\\\\burnout-datathon-ieeecsmuj\\\\sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec0a845-2818-4efe-a001-a9d2c3e9dd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 3) Briefly visualize the data\\nprint(train.head())\\nprint(train.describe())\\nsns.histplot(train[\\'Lap_Time_Seconds\\'], kde=True)\\nplt.title(\"Distribution of Lap Time Seconds\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 3) Briefly visualize the data\n",
    "print(train.head())\n",
    "print(train.describe())\n",
    "sns.histplot(train['Lap_Time_Seconds'], kde=True)\n",
    "plt.title(\"Distribution of Lap Time Seconds\")\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb176dd7-e8cf-42b4-b3c9-ba432f657999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Add features\n",
    "def add_features(df):\n",
    "    df['LapTime_Estimate'] = df['Circuit_Length_km'] / df['Avg_Speed_kmh'] * 3600\n",
    "    df['Points_per_Year'] = df['Championship_Points'] / (df['years_active'] + 1)\n",
    "    df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
    "    df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
    "    df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
    "    df['Avg_Temp'] = (df['Ambient_Temperature_Celsius'] + df['Track_Temperature_Celsius']) / 2\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "TARGET = 'Lap_Time_Seconds'\n",
    "DROP_COLS = [\n",
    "    'Unique ID', 'rider_name', 'team_name', 'bike_name',\n",
    "    'circuit_name', 'points', 'position'\n",
    "]\n",
    "\n",
    "X = train.drop(DROP_COLS + [TARGET], axis=1)\n",
    "y = train[TARGET]\n",
    "X_test = test.drop(DROP_COLS, axis=1)\n",
    "\n",
    "# Handle missing values and categorical encoding\n",
    "all_data = pd.concat([X, X_test], axis=0)\n",
    "all_data.fillna(-1, inplace=True)\n",
    "cat_cols = all_data.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    all_data[col] = all_data[col].astype('category').cat.codes\n",
    "\n",
    "X = all_data.iloc[:len(train)]\n",
    "X_test = all_data.iloc[len(train):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6c1c45-5a78-400d-b8c1-11cb148b8f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 10.824\tvalid_1's rmse: 10.8598\n",
      "[50]\ttraining's rmse: 10.2332\tvalid_1's rmse: 10.2862\n",
      "[75]\ttraining's rmse: 9.72054\tvalid_1's rmse: 9.78304\n",
      "[100]\ttraining's rmse: 9.2067\tvalid_1's rmse: 9.28111\n",
      "[125]\ttraining's rmse: 8.73666\tvalid_1's rmse: 8.81529\n",
      "[150]\ttraining's rmse: 8.32399\tvalid_1's rmse: 8.4122\n",
      "[175]\ttraining's rmse: 7.95797\tvalid_1's rmse: 8.04966\n",
      "[200]\ttraining's rmse: 7.61613\tvalid_1's rmse: 7.70812\n",
      "[225]\ttraining's rmse: 7.2798\tvalid_1's rmse: 7.37421\n",
      "[250]\ttraining's rmse: 6.94777\tvalid_1's rmse: 7.05142\n",
      "[275]\ttraining's rmse: 6.62318\tvalid_1's rmse: 6.73175\n",
      "[300]\ttraining's rmse: 6.34098\tvalid_1's rmse: 6.45071\n",
      "[325]\ttraining's rmse: 6.06698\tvalid_1's rmse: 6.17816\n",
      "[350]\ttraining's rmse: 5.79612\tvalid_1's rmse: 5.90997\n",
      "[375]\ttraining's rmse: 5.55355\tvalid_1's rmse: 5.67072\n",
      "[400]\ttraining's rmse: 5.31546\tvalid_1's rmse: 5.43462\n",
      "[425]\ttraining's rmse: 5.09525\tvalid_1's rmse: 5.21722\n",
      "[450]\ttraining's rmse: 4.89078\tvalid_1's rmse: 5.01014\n",
      "[475]\ttraining's rmse: 4.68986\tvalid_1's rmse: 4.80991\n",
      "[500]\ttraining's rmse: 4.4941\tvalid_1's rmse: 4.61464\n",
      "[525]\ttraining's rmse: 4.32132\tvalid_1's rmse: 4.4415\n",
      "[550]\ttraining's rmse: 4.15924\tvalid_1's rmse: 4.28003\n",
      "[575]\ttraining's rmse: 3.98424\tvalid_1's rmse: 4.10541\n",
      "[600]\ttraining's rmse: 3.81602\tvalid_1's rmse: 3.936\n",
      "[625]\ttraining's rmse: 3.65761\tvalid_1's rmse: 3.77793\n",
      "[650]\ttraining's rmse: 3.50213\tvalid_1's rmse: 3.62242\n",
      "[675]\ttraining's rmse: 3.36577\tvalid_1's rmse: 3.48547\n",
      "[700]\ttraining's rmse: 3.22203\tvalid_1's rmse: 3.34087\n",
      "[725]\ttraining's rmse: 3.09586\tvalid_1's rmse: 3.21303\n",
      "[750]\ttraining's rmse: 2.9591\tvalid_1's rmse: 3.07472\n",
      "[775]\ttraining's rmse: 2.84376\tvalid_1's rmse: 2.958\n",
      "[800]\ttraining's rmse: 2.74383\tvalid_1's rmse: 2.85775\n",
      "[825]\ttraining's rmse: 2.64246\tvalid_1's rmse: 2.75549\n",
      "[850]\ttraining's rmse: 2.53965\tvalid_1's rmse: 2.65083\n",
      "[875]\ttraining's rmse: 2.43751\tvalid_1's rmse: 2.54663\n",
      "[900]\ttraining's rmse: 2.33663\tvalid_1's rmse: 2.44322\n",
      "[925]\ttraining's rmse: 2.24036\tvalid_1's rmse: 2.34548\n",
      "[950]\ttraining's rmse: 2.17137\tvalid_1's rmse: 2.27534\n",
      "[975]\ttraining's rmse: 2.07127\tvalid_1's rmse: 2.17333\n",
      "[1000]\ttraining's rmse: 1.994\tvalid_1's rmse: 2.0935\n",
      "[1025]\ttraining's rmse: 1.91083\tvalid_1's rmse: 2.00771\n",
      "[1050]\ttraining's rmse: 1.8361\tvalid_1's rmse: 1.93187\n",
      "[1075]\ttraining's rmse: 1.7748\tvalid_1's rmse: 1.86948\n",
      "[1100]\ttraining's rmse: 1.70277\tvalid_1's rmse: 1.79566\n",
      "[1125]\ttraining's rmse: 1.64013\tvalid_1's rmse: 1.73044\n",
      "[1150]\ttraining's rmse: 1.5779\tvalid_1's rmse: 1.66792\n",
      "[1175]\ttraining's rmse: 1.52199\tvalid_1's rmse: 1.60995\n",
      "[1200]\ttraining's rmse: 1.46789\tvalid_1's rmse: 1.55424\n",
      "[1225]\ttraining's rmse: 1.41536\tvalid_1's rmse: 1.49958\n",
      "[1250]\ttraining's rmse: 1.36672\tvalid_1's rmse: 1.44922\n",
      "[1275]\ttraining's rmse: 1.31665\tvalid_1's rmse: 1.39761\n",
      "[1300]\ttraining's rmse: 1.27332\tvalid_1's rmse: 1.3532\n",
      "[1325]\ttraining's rmse: 1.226\tvalid_1's rmse: 1.30403\n",
      "[1350]\ttraining's rmse: 1.17909\tvalid_1's rmse: 1.25518\n",
      "[1375]\ttraining's rmse: 1.14172\tvalid_1's rmse: 1.21646\n",
      "[1400]\ttraining's rmse: 1.10314\tvalid_1's rmse: 1.1767\n",
      "[1425]\ttraining's rmse: 1.06539\tvalid_1's rmse: 1.13785\n",
      "[1450]\ttraining's rmse: 1.02745\tvalid_1's rmse: 1.09826\n",
      "[1475]\ttraining's rmse: 0.987142\tvalid_1's rmse: 1.05629\n",
      "[1500]\ttraining's rmse: 0.948902\tvalid_1's rmse: 1.01682\n",
      "[1525]\ttraining's rmse: 0.918024\tvalid_1's rmse: 0.984478\n",
      "[1550]\ttraining's rmse: 0.883596\tvalid_1's rmse: 0.949005\n",
      "[1575]\ttraining's rmse: 0.85305\tvalid_1's rmse: 0.917378\n",
      "[1600]\ttraining's rmse: 0.827046\tvalid_1's rmse: 0.890573\n",
      "[1625]\ttraining's rmse: 0.800929\tvalid_1's rmse: 0.863226\n",
      "[1650]\ttraining's rmse: 0.776643\tvalid_1's rmse: 0.838006\n",
      "[1675]\ttraining's rmse: 0.752337\tvalid_1's rmse: 0.813293\n",
      "[1700]\ttraining's rmse: 0.72947\tvalid_1's rmse: 0.789385\n",
      "[1725]\ttraining's rmse: 0.705632\tvalid_1's rmse: 0.764312\n",
      "[1750]\ttraining's rmse: 0.683845\tvalid_1's rmse: 0.741242\n",
      "[1775]\ttraining's rmse: 0.66522\tvalid_1's rmse: 0.721839\n",
      "[1800]\ttraining's rmse: 0.642063\tvalid_1's rmse: 0.697378\n",
      "[1825]\ttraining's rmse: 0.623345\tvalid_1's rmse: 0.67816\n",
      "[1850]\ttraining's rmse: 0.607396\tvalid_1's rmse: 0.661642\n",
      "[1875]\ttraining's rmse: 0.593874\tvalid_1's rmse: 0.64776\n",
      "[1900]\ttraining's rmse: 0.57565\tvalid_1's rmse: 0.628415\n",
      "[1925]\ttraining's rmse: 0.561598\tvalid_1's rmse: 0.613831\n",
      "[1950]\ttraining's rmse: 0.546505\tvalid_1's rmse: 0.598024\n",
      "[1975]\ttraining's rmse: 0.531307\tvalid_1's rmse: 0.582022\n",
      "[2000]\ttraining's rmse: 0.518358\tvalid_1's rmse: 0.568128\n",
      "[2025]\ttraining's rmse: 0.504965\tvalid_1's rmse: 0.554188\n",
      "[2050]\ttraining's rmse: 0.492266\tvalid_1's rmse: 0.54055\n",
      "[2075]\ttraining's rmse: 0.479924\tvalid_1's rmse: 0.527842\n",
      "[2100]\ttraining's rmse: 0.469347\tvalid_1's rmse: 0.516657\n",
      "[2125]\ttraining's rmse: 0.459419\tvalid_1's rmse: 0.506218\n",
      "[2150]\ttraining's rmse: 0.44742\tvalid_1's rmse: 0.493596\n",
      "[2175]\ttraining's rmse: 0.437162\tvalid_1's rmse: 0.482882\n",
      "[2200]\ttraining's rmse: 0.427336\tvalid_1's rmse: 0.472441\n",
      "[2225]\ttraining's rmse: 0.418271\tvalid_1's rmse: 0.462833\n",
      "[2250]\ttraining's rmse: 0.410022\tvalid_1's rmse: 0.454038\n",
      "[2275]\ttraining's rmse: 0.402432\tvalid_1's rmse: 0.446069\n",
      "[2300]\ttraining's rmse: 0.394713\tvalid_1's rmse: 0.437783\n",
      "[2325]\ttraining's rmse: 0.386014\tvalid_1's rmse: 0.428275\n",
      "[2350]\ttraining's rmse: 0.378181\tvalid_1's rmse: 0.419773\n",
      "[2375]\ttraining's rmse: 0.371694\tvalid_1's rmse: 0.41284\n",
      "[2400]\ttraining's rmse: 0.365346\tvalid_1's rmse: 0.406031\n",
      "[2425]\ttraining's rmse: 0.359564\tvalid_1's rmse: 0.399737\n",
      "[2450]\ttraining's rmse: 0.354746\tvalid_1's rmse: 0.394721\n",
      "[2475]\ttraining's rmse: 0.348899\tvalid_1's rmse: 0.388506\n",
      "[2500]\ttraining's rmse: 0.343016\tvalid_1's rmse: 0.382084\n",
      "[2525]\ttraining's rmse: 0.337862\tvalid_1's rmse: 0.376431\n",
      "[2550]\ttraining's rmse: 0.333675\tvalid_1's rmse: 0.372125\n",
      "[2575]\ttraining's rmse: 0.327912\tvalid_1's rmse: 0.365931\n",
      "[2600]\ttraining's rmse: 0.322831\tvalid_1's rmse: 0.360466\n",
      "[2625]\ttraining's rmse: 0.318907\tvalid_1's rmse: 0.356431\n",
      "[2650]\ttraining's rmse: 0.314247\tvalid_1's rmse: 0.351263\n",
      "[2675]\ttraining's rmse: 0.310479\tvalid_1's rmse: 0.347232\n",
      "[2700]\ttraining's rmse: 0.306656\tvalid_1's rmse: 0.343118\n",
      "[2725]\ttraining's rmse: 0.302721\tvalid_1's rmse: 0.338869\n",
      "[2750]\ttraining's rmse: 0.299232\tvalid_1's rmse: 0.335279\n",
      "[2775]\ttraining's rmse: 0.295971\tvalid_1's rmse: 0.331711\n",
      "[2800]\ttraining's rmse: 0.293445\tvalid_1's rmse: 0.329208\n",
      "[2825]\ttraining's rmse: 0.290712\tvalid_1's rmse: 0.326387\n",
      "[2850]\ttraining's rmse: 0.287665\tvalid_1's rmse: 0.323195\n",
      "[2875]\ttraining's rmse: 0.284883\tvalid_1's rmse: 0.320262\n",
      "[2900]\ttraining's rmse: 0.282211\tvalid_1's rmse: 0.317379\n",
      "[2925]\ttraining's rmse: 0.280178\tvalid_1's rmse: 0.315478\n",
      "[2950]\ttraining's rmse: 0.277416\tvalid_1's rmse: 0.312787\n",
      "[2975]\ttraining's rmse: 0.274848\tvalid_1's rmse: 0.310233\n",
      "[3000]\ttraining's rmse: 0.272722\tvalid_1's rmse: 0.308113\n",
      "[3025]\ttraining's rmse: 0.270917\tvalid_1's rmse: 0.306493\n",
      "[3050]\ttraining's rmse: 0.268611\tvalid_1's rmse: 0.304197\n",
      "[3075]\ttraining's rmse: 0.266396\tvalid_1's rmse: 0.3019\n",
      "[3100]\ttraining's rmse: 0.264182\tvalid_1's rmse: 0.299642\n",
      "[3125]\ttraining's rmse: 0.262752\tvalid_1's rmse: 0.298377\n",
      "[3150]\ttraining's rmse: 0.260672\tvalid_1's rmse: 0.296286\n",
      "[3175]\ttraining's rmse: 0.258991\tvalid_1's rmse: 0.294632\n",
      "[3200]\ttraining's rmse: 0.256898\tvalid_1's rmse: 0.292411\n",
      "[3225]\ttraining's rmse: 0.25534\tvalid_1's rmse: 0.290934\n",
      "[3250]\ttraining's rmse: 0.253566\tvalid_1's rmse: 0.289216\n",
      "[3275]\ttraining's rmse: 0.251922\tvalid_1's rmse: 0.287714\n",
      "[3300]\ttraining's rmse: 0.250183\tvalid_1's rmse: 0.285906\n",
      "[3325]\ttraining's rmse: 0.248794\tvalid_1's rmse: 0.284728\n",
      "[3350]\ttraining's rmse: 0.247417\tvalid_1's rmse: 0.283486\n",
      "[3375]\ttraining's rmse: 0.246081\tvalid_1's rmse: 0.282264\n",
      "[3400]\ttraining's rmse: 0.245012\tvalid_1's rmse: 0.281446\n",
      "[3425]\ttraining's rmse: 0.243906\tvalid_1's rmse: 0.280538\n",
      "[3450]\ttraining's rmse: 0.242687\tvalid_1's rmse: 0.279531\n",
      "[3475]\ttraining's rmse: 0.241383\tvalid_1's rmse: 0.278336\n",
      "[3500]\ttraining's rmse: 0.240072\tvalid_1's rmse: 0.27713\n",
      "[3525]\ttraining's rmse: 0.238738\tvalid_1's rmse: 0.275991\n",
      "[3550]\ttraining's rmse: 0.237393\tvalid_1's rmse: 0.2748\n",
      "[3575]\ttraining's rmse: 0.236296\tvalid_1's rmse: 0.273898\n",
      "[3600]\ttraining's rmse: 0.235224\tvalid_1's rmse: 0.272967\n",
      "[3625]\ttraining's rmse: 0.234143\tvalid_1's rmse: 0.271993\n",
      "[3650]\ttraining's rmse: 0.233266\tvalid_1's rmse: 0.27132\n",
      "[3675]\ttraining's rmse: 0.232238\tvalid_1's rmse: 0.270549\n",
      "[3700]\ttraining's rmse: 0.231226\tvalid_1's rmse: 0.269705\n",
      "[3725]\ttraining's rmse: 0.230226\tvalid_1's rmse: 0.268893\n",
      "[3750]\ttraining's rmse: 0.229319\tvalid_1's rmse: 0.268147\n",
      "[3775]\ttraining's rmse: 0.228357\tvalid_1's rmse: 0.26735\n",
      "[3800]\ttraining's rmse: 0.227406\tvalid_1's rmse: 0.266632\n",
      "[3825]\ttraining's rmse: 0.226333\tvalid_1's rmse: 0.265817\n",
      "[3850]\ttraining's rmse: 0.225533\tvalid_1's rmse: 0.265312\n",
      "[3875]\ttraining's rmse: 0.2246\tvalid_1's rmse: 0.264594\n",
      "[3900]\ttraining's rmse: 0.223653\tvalid_1's rmse: 0.263792\n",
      "[3925]\ttraining's rmse: 0.222913\tvalid_1's rmse: 0.263285\n",
      "[3950]\ttraining's rmse: 0.22174\tvalid_1's rmse: 0.262173\n",
      "[3975]\ttraining's rmse: 0.221032\tvalid_1's rmse: 0.261719\n",
      "[4000]\ttraining's rmse: 0.220208\tvalid_1's rmse: 0.261157\n",
      "[4025]\ttraining's rmse: 0.219144\tvalid_1's rmse: 0.260295\n",
      "[4050]\ttraining's rmse: 0.218317\tvalid_1's rmse: 0.259671\n",
      "[4075]\ttraining's rmse: 0.217669\tvalid_1's rmse: 0.259323\n",
      "[4100]\ttraining's rmse: 0.216888\tvalid_1's rmse: 0.258695\n",
      "[4125]\ttraining's rmse: 0.216111\tvalid_1's rmse: 0.258144\n",
      "[4150]\ttraining's rmse: 0.215426\tvalid_1's rmse: 0.257747\n",
      "[4175]\ttraining's rmse: 0.214761\tvalid_1's rmse: 0.257329\n",
      "[4200]\ttraining's rmse: 0.214097\tvalid_1's rmse: 0.256929\n",
      "[4225]\ttraining's rmse: 0.213474\tvalid_1's rmse: 0.256564\n",
      "[4250]\ttraining's rmse: 0.212774\tvalid_1's rmse: 0.256134\n",
      "[4275]\ttraining's rmse: 0.212083\tvalid_1's rmse: 0.255627\n",
      "[4300]\ttraining's rmse: 0.211423\tvalid_1's rmse: 0.255195\n",
      "[4325]\ttraining's rmse: 0.210727\tvalid_1's rmse: 0.254723\n",
      "[4350]\ttraining's rmse: 0.209964\tvalid_1's rmse: 0.254136\n",
      "[4375]\ttraining's rmse: 0.209227\tvalid_1's rmse: 0.253591\n",
      "[4400]\ttraining's rmse: 0.208554\tvalid_1's rmse: 0.253082\n",
      "[4425]\ttraining's rmse: 0.207947\tvalid_1's rmse: 0.25274\n",
      "[4450]\ttraining's rmse: 0.207202\tvalid_1's rmse: 0.252152\n",
      "[4475]\ttraining's rmse: 0.206585\tvalid_1's rmse: 0.25181\n",
      "[4500]\ttraining's rmse: 0.205986\tvalid_1's rmse: 0.25144\n",
      "[4525]\ttraining's rmse: 0.20537\tvalid_1's rmse: 0.251078\n",
      "[4550]\ttraining's rmse: 0.204702\tvalid_1's rmse: 0.250625\n",
      "[4575]\ttraining's rmse: 0.204173\tvalid_1's rmse: 0.25036\n",
      "[4600]\ttraining's rmse: 0.203601\tvalid_1's rmse: 0.250047\n",
      "[4625]\ttraining's rmse: 0.20301\tvalid_1's rmse: 0.249715\n",
      "[4650]\ttraining's rmse: 0.20249\tvalid_1's rmse: 0.249465\n",
      "[4675]\ttraining's rmse: 0.201814\tvalid_1's rmse: 0.249018\n",
      "[4700]\ttraining's rmse: 0.201222\tvalid_1's rmse: 0.248665\n",
      "[4725]\ttraining's rmse: 0.200649\tvalid_1's rmse: 0.248343\n",
      "[4750]\ttraining's rmse: 0.200127\tvalid_1's rmse: 0.248037\n",
      "[4775]\ttraining's rmse: 0.199547\tvalid_1's rmse: 0.247675\n",
      "[4800]\ttraining's rmse: 0.199092\tvalid_1's rmse: 0.247501\n",
      "[4825]\ttraining's rmse: 0.198562\tvalid_1's rmse: 0.2472\n",
      "[4850]\ttraining's rmse: 0.198025\tvalid_1's rmse: 0.24687\n",
      "[4875]\ttraining's rmse: 0.197515\tvalid_1's rmse: 0.24662\n",
      "[4900]\ttraining's rmse: 0.196973\tvalid_1's rmse: 0.24632\n",
      "[4925]\ttraining's rmse: 0.196387\tvalid_1's rmse: 0.245929\n",
      "[4950]\ttraining's rmse: 0.195932\tvalid_1's rmse: 0.245709\n",
      "[4975]\ttraining's rmse: 0.195401\tvalid_1's rmse: 0.245374\n",
      "[5000]\ttraining's rmse: 0.194872\tvalid_1's rmse: 0.245076\n",
      "[5025]\ttraining's rmse: 0.194365\tvalid_1's rmse: 0.24478\n",
      "[5050]\ttraining's rmse: 0.193865\tvalid_1's rmse: 0.244509\n",
      "[5075]\ttraining's rmse: 0.193382\tvalid_1's rmse: 0.244237\n",
      "[5100]\ttraining's rmse: 0.192897\tvalid_1's rmse: 0.243995\n",
      "[5125]\ttraining's rmse: 0.192512\tvalid_1's rmse: 0.243895\n",
      "[5150]\ttraining's rmse: 0.191877\tvalid_1's rmse: 0.243427\n",
      "[5175]\ttraining's rmse: 0.191408\tvalid_1's rmse: 0.243156\n",
      "[5200]\ttraining's rmse: 0.190953\tvalid_1's rmse: 0.242901\n",
      "[5225]\ttraining's rmse: 0.190407\tvalid_1's rmse: 0.242576\n",
      "[5250]\ttraining's rmse: 0.190021\tvalid_1's rmse: 0.242437\n",
      "[5275]\ttraining's rmse: 0.189573\tvalid_1's rmse: 0.242176\n",
      "[5300]\ttraining's rmse: 0.189137\tvalid_1's rmse: 0.241924\n",
      "[5325]\ttraining's rmse: 0.188671\tvalid_1's rmse: 0.241687\n",
      "[5350]\ttraining's rmse: 0.188286\tvalid_1's rmse: 0.241558\n",
      "[5375]\ttraining's rmse: 0.187887\tvalid_1's rmse: 0.241382\n",
      "[5400]\ttraining's rmse: 0.187504\tvalid_1's rmse: 0.24122\n",
      "[5425]\ttraining's rmse: 0.187082\tvalid_1's rmse: 0.24104\n",
      "[5450]\ttraining's rmse: 0.186612\tvalid_1's rmse: 0.240773\n",
      "[5475]\ttraining's rmse: 0.18623\tvalid_1's rmse: 0.240636\n",
      "[5500]\ttraining's rmse: 0.185767\tvalid_1's rmse: 0.240409\n",
      "[5525]\ttraining's rmse: 0.185371\tvalid_1's rmse: 0.240256\n",
      "[5550]\ttraining's rmse: 0.184967\tvalid_1's rmse: 0.240021\n",
      "[5575]\ttraining's rmse: 0.184569\tvalid_1's rmse: 0.239855\n",
      "[5600]\ttraining's rmse: 0.184174\tvalid_1's rmse: 0.239648\n",
      "[5625]\ttraining's rmse: 0.183778\tvalid_1's rmse: 0.239485\n",
      "[5650]\ttraining's rmse: 0.183388\tvalid_1's rmse: 0.239322\n",
      "[5675]\ttraining's rmse: 0.182908\tvalid_1's rmse: 0.239113\n",
      "[5700]\ttraining's rmse: 0.182532\tvalid_1's rmse: 0.238952\n",
      "[5725]\ttraining's rmse: 0.18209\tvalid_1's rmse: 0.238697\n",
      "[5750]\ttraining's rmse: 0.181707\tvalid_1's rmse: 0.238554\n",
      "[5775]\ttraining's rmse: 0.181361\tvalid_1's rmse: 0.238465\n",
      "[5800]\ttraining's rmse: 0.181002\tvalid_1's rmse: 0.238306\n",
      "[5825]\ttraining's rmse: 0.180648\tvalid_1's rmse: 0.23816\n",
      "[5850]\ttraining's rmse: 0.180212\tvalid_1's rmse: 0.237932\n",
      "[5875]\ttraining's rmse: 0.179875\tvalid_1's rmse: 0.237826\n",
      "[5900]\ttraining's rmse: 0.179507\tvalid_1's rmse: 0.237643\n",
      "[5925]\ttraining's rmse: 0.179127\tvalid_1's rmse: 0.23748\n",
      "[5950]\ttraining's rmse: 0.178701\tvalid_1's rmse: 0.237279\n",
      "[5975]\ttraining's rmse: 0.17829\tvalid_1's rmse: 0.237047\n",
      "[6000]\ttraining's rmse: 0.177927\tvalid_1's rmse: 0.236902\n",
      "[6025]\ttraining's rmse: 0.17758\tvalid_1's rmse: 0.236763\n",
      "[6050]\ttraining's rmse: 0.177239\tvalid_1's rmse: 0.236627\n",
      "[6075]\ttraining's rmse: 0.176847\tvalid_1's rmse: 0.236448\n",
      "[6100]\ttraining's rmse: 0.17651\tvalid_1's rmse: 0.236314\n",
      "[6125]\ttraining's rmse: 0.176174\tvalid_1's rmse: 0.236205\n",
      "[6150]\ttraining's rmse: 0.175823\tvalid_1's rmse: 0.236082\n",
      "[6175]\ttraining's rmse: 0.175482\tvalid_1's rmse: 0.235935\n",
      "[6200]\ttraining's rmse: 0.175156\tvalid_1's rmse: 0.235807\n",
      "[6225]\ttraining's rmse: 0.174808\tvalid_1's rmse: 0.235655\n",
      "[6250]\ttraining's rmse: 0.174465\tvalid_1's rmse: 0.235521\n",
      "[6275]\ttraining's rmse: 0.174118\tvalid_1's rmse: 0.235345\n",
      "[6300]\ttraining's rmse: 0.17378\tvalid_1's rmse: 0.235193\n",
      "[6325]\ttraining's rmse: 0.173431\tvalid_1's rmse: 0.235071\n",
      "[6350]\ttraining's rmse: 0.173121\tvalid_1's rmse: 0.234966\n",
      "[6375]\ttraining's rmse: 0.172756\tvalid_1's rmse: 0.234826\n",
      "[6400]\ttraining's rmse: 0.172438\tvalid_1's rmse: 0.234706\n",
      "[6425]\ttraining's rmse: 0.172131\tvalid_1's rmse: 0.234603\n",
      "[6450]\ttraining's rmse: 0.171826\tvalid_1's rmse: 0.234512\n",
      "[6475]\ttraining's rmse: 0.171495\tvalid_1's rmse: 0.234351\n",
      "[6500]\ttraining's rmse: 0.171162\tvalid_1's rmse: 0.234222\n",
      "[6525]\ttraining's rmse: 0.170793\tvalid_1's rmse: 0.234053\n",
      "[6550]\ttraining's rmse: 0.170476\tvalid_1's rmse: 0.233948\n",
      "[6575]\ttraining's rmse: 0.170139\tvalid_1's rmse: 0.233849\n",
      "[6600]\ttraining's rmse: 0.169848\tvalid_1's rmse: 0.233757\n",
      "[6625]\ttraining's rmse: 0.169521\tvalid_1's rmse: 0.233592\n",
      "[6650]\ttraining's rmse: 0.169139\tvalid_1's rmse: 0.233398\n",
      "[6675]\ttraining's rmse: 0.168806\tvalid_1's rmse: 0.233258\n",
      "[6700]\ttraining's rmse: 0.16853\tvalid_1's rmse: 0.233195\n",
      "[6725]\ttraining's rmse: 0.16822\tvalid_1's rmse: 0.233083\n",
      "[6750]\ttraining's rmse: 0.167897\tvalid_1's rmse: 0.232939\n",
      "[6775]\ttraining's rmse: 0.167592\tvalid_1's rmse: 0.23283\n",
      "[6800]\ttraining's rmse: 0.167262\tvalid_1's rmse: 0.232679\n",
      "[6825]\ttraining's rmse: 0.166963\tvalid_1's rmse: 0.232564\n",
      "[6850]\ttraining's rmse: 0.166676\tvalid_1's rmse: 0.232466\n",
      "[6875]\ttraining's rmse: 0.166378\tvalid_1's rmse: 0.232335\n",
      "[6900]\ttraining's rmse: 0.166094\tvalid_1's rmse: 0.232241\n",
      "[6925]\ttraining's rmse: 0.165805\tvalid_1's rmse: 0.232169\n",
      "[6950]\ttraining's rmse: 0.165469\tvalid_1's rmse: 0.232021\n",
      "[6975]\ttraining's rmse: 0.165203\tvalid_1's rmse: 0.231941\n",
      "[7000]\ttraining's rmse: 0.164926\tvalid_1's rmse: 0.23185\n",
      "[7025]\ttraining's rmse: 0.164656\tvalid_1's rmse: 0.231778\n",
      "[7050]\ttraining's rmse: 0.164339\tvalid_1's rmse: 0.231642\n",
      "[7075]\ttraining's rmse: 0.16403\tvalid_1's rmse: 0.231533\n",
      "[7100]\ttraining's rmse: 0.163758\tvalid_1's rmse: 0.231452\n",
      "[7125]\ttraining's rmse: 0.163488\tvalid_1's rmse: 0.231362\n",
      "[7150]\ttraining's rmse: 0.163227\tvalid_1's rmse: 0.231296\n",
      "[7175]\ttraining's rmse: 0.162967\tvalid_1's rmse: 0.231241\n",
      "[7200]\ttraining's rmse: 0.162713\tvalid_1's rmse: 0.231187\n",
      "[7225]\ttraining's rmse: 0.162449\tvalid_1's rmse: 0.23109\n",
      "[7250]\ttraining's rmse: 0.162216\tvalid_1's rmse: 0.231069\n",
      "[7275]\ttraining's rmse: 0.161954\tvalid_1's rmse: 0.230994\n",
      "[7300]\ttraining's rmse: 0.161662\tvalid_1's rmse: 0.230896\n",
      "[7325]\ttraining's rmse: 0.161319\tvalid_1's rmse: 0.230729\n",
      "[7350]\ttraining's rmse: 0.161049\tvalid_1's rmse: 0.230647\n",
      "[7375]\ttraining's rmse: 0.160759\tvalid_1's rmse: 0.230542\n",
      "[7400]\ttraining's rmse: 0.160495\tvalid_1's rmse: 0.23046\n",
      "[7425]\ttraining's rmse: 0.160215\tvalid_1's rmse: 0.230348\n",
      "[7450]\ttraining's rmse: 0.159933\tvalid_1's rmse: 0.230253\n",
      "[7475]\ttraining's rmse: 0.159681\tvalid_1's rmse: 0.230188\n",
      "[7500]\ttraining's rmse: 0.159343\tvalid_1's rmse: 0.230021\n",
      "[7525]\ttraining's rmse: 0.159058\tvalid_1's rmse: 0.229907\n",
      "[7550]\ttraining's rmse: 0.158793\tvalid_1's rmse: 0.229792\n",
      "[7575]\ttraining's rmse: 0.158525\tvalid_1's rmse: 0.229685\n",
      "[7600]\ttraining's rmse: 0.158258\tvalid_1's rmse: 0.229589\n",
      "[7625]\ttraining's rmse: 0.157986\tvalid_1's rmse: 0.229493\n",
      "[7650]\ttraining's rmse: 0.157716\tvalid_1's rmse: 0.22941\n",
      "[7675]\ttraining's rmse: 0.157478\tvalid_1's rmse: 0.229348\n",
      "[7700]\ttraining's rmse: 0.157233\tvalid_1's rmse: 0.229265\n",
      "[7725]\ttraining's rmse: 0.156995\tvalid_1's rmse: 0.229198\n",
      "[7750]\ttraining's rmse: 0.156735\tvalid_1's rmse: 0.229116\n",
      "[7775]\ttraining's rmse: 0.15649\tvalid_1's rmse: 0.229049\n",
      "[7800]\ttraining's rmse: 0.156275\tvalid_1's rmse: 0.229021\n",
      "[7825]\ttraining's rmse: 0.156033\tvalid_1's rmse: 0.228942\n",
      "[7850]\ttraining's rmse: 0.155796\tvalid_1's rmse: 0.228864\n",
      "[7875]\ttraining's rmse: 0.155492\tvalid_1's rmse: 0.228726\n",
      "[7900]\ttraining's rmse: 0.155228\tvalid_1's rmse: 0.228598\n",
      "[7925]\ttraining's rmse: 0.155003\tvalid_1's rmse: 0.228563\n",
      "[7950]\ttraining's rmse: 0.154773\tvalid_1's rmse: 0.228492\n",
      "[7975]\ttraining's rmse: 0.154523\tvalid_1's rmse: 0.228395\n",
      "[8000]\ttraining's rmse: 0.154284\tvalid_1's rmse: 0.228313\n",
      "[8025]\ttraining's rmse: 0.154053\tvalid_1's rmse: 0.228255\n",
      "[8050]\ttraining's rmse: 0.153829\tvalid_1's rmse: 0.228208\n",
      "[8075]\ttraining's rmse: 0.153613\tvalid_1's rmse: 0.228148\n",
      "[8100]\ttraining's rmse: 0.153404\tvalid_1's rmse: 0.228112\n",
      "[8125]\ttraining's rmse: 0.153183\tvalid_1's rmse: 0.228052\n",
      "[8150]\ttraining's rmse: 0.15296\tvalid_1's rmse: 0.227984\n",
      "[8175]\ttraining's rmse: 0.152747\tvalid_1's rmse: 0.227949\n",
      "[8200]\ttraining's rmse: 0.152528\tvalid_1's rmse: 0.227902\n",
      "[8225]\ttraining's rmse: 0.152303\tvalid_1's rmse: 0.227844\n",
      "[8250]\ttraining's rmse: 0.152061\tvalid_1's rmse: 0.227761\n",
      "[8275]\ttraining's rmse: 0.151848\tvalid_1's rmse: 0.227725\n",
      "[8300]\ttraining's rmse: 0.151604\tvalid_1's rmse: 0.227637\n",
      "[8325]\ttraining's rmse: 0.151376\tvalid_1's rmse: 0.227577\n",
      "[8350]\ttraining's rmse: 0.15114\tvalid_1's rmse: 0.227507\n",
      "[8375]\ttraining's rmse: 0.150921\tvalid_1's rmse: 0.227452\n",
      "[8400]\ttraining's rmse: 0.150706\tvalid_1's rmse: 0.227408\n",
      "[8425]\ttraining's rmse: 0.150499\tvalid_1's rmse: 0.227359\n",
      "[8450]\ttraining's rmse: 0.150284\tvalid_1's rmse: 0.227321\n",
      "[8475]\ttraining's rmse: 0.150046\tvalid_1's rmse: 0.227223\n",
      "[8500]\ttraining's rmse: 0.149833\tvalid_1's rmse: 0.227183\n",
      "[8525]\ttraining's rmse: 0.149622\tvalid_1's rmse: 0.227124\n",
      "[8550]\ttraining's rmse: 0.149426\tvalid_1's rmse: 0.227092\n",
      "[8575]\ttraining's rmse: 0.149202\tvalid_1's rmse: 0.227052\n",
      "[8600]\ttraining's rmse: 0.148961\tvalid_1's rmse: 0.226957\n",
      "[8625]\ttraining's rmse: 0.148725\tvalid_1's rmse: 0.226869\n",
      "[8650]\ttraining's rmse: 0.148523\tvalid_1's rmse: 0.226828\n",
      "[8675]\ttraining's rmse: 0.1483\tvalid_1's rmse: 0.226764\n",
      "[8700]\ttraining's rmse: 0.14809\tvalid_1's rmse: 0.22671\n",
      "[8725]\ttraining's rmse: 0.147867\tvalid_1's rmse: 0.226639\n",
      "[8750]\ttraining's rmse: 0.147675\tvalid_1's rmse: 0.226599\n",
      "[8775]\ttraining's rmse: 0.147467\tvalid_1's rmse: 0.226556\n",
      "[8800]\ttraining's rmse: 0.147255\tvalid_1's rmse: 0.226488\n",
      "[8825]\ttraining's rmse: 0.147052\tvalid_1's rmse: 0.226433\n",
      "[8850]\ttraining's rmse: 0.146859\tvalid_1's rmse: 0.226403\n",
      "[8875]\ttraining's rmse: 0.146664\tvalid_1's rmse: 0.226353\n",
      "[8900]\ttraining's rmse: 0.146453\tvalid_1's rmse: 0.2263\n",
      "[8925]\ttraining's rmse: 0.146263\tvalid_1's rmse: 0.22627\n",
      "[8950]\ttraining's rmse: 0.146069\tvalid_1's rmse: 0.226229\n",
      "[8975]\ttraining's rmse: 0.145871\tvalid_1's rmse: 0.2262\n",
      "[9000]\ttraining's rmse: 0.14564\tvalid_1's rmse: 0.226108\n",
      "[9025]\ttraining's rmse: 0.145433\tvalid_1's rmse: 0.226031\n",
      "[9050]\ttraining's rmse: 0.145211\tvalid_1's rmse: 0.225951\n",
      "[9075]\ttraining's rmse: 0.14502\tvalid_1's rmse: 0.225925\n",
      "[9100]\ttraining's rmse: 0.144819\tvalid_1's rmse: 0.225876\n",
      "[9125]\ttraining's rmse: 0.144611\tvalid_1's rmse: 0.225819\n",
      "[9150]\ttraining's rmse: 0.144419\tvalid_1's rmse: 0.225782\n",
      "[9175]\ttraining's rmse: 0.14422\tvalid_1's rmse: 0.225743\n",
      "[9200]\ttraining's rmse: 0.144033\tvalid_1's rmse: 0.225721\n",
      "[9225]\ttraining's rmse: 0.143846\tvalid_1's rmse: 0.225685\n",
      "[9250]\ttraining's rmse: 0.143664\tvalid_1's rmse: 0.225638\n",
      "[9275]\ttraining's rmse: 0.143472\tvalid_1's rmse: 0.225602\n",
      "[9300]\ttraining's rmse: 0.143274\tvalid_1's rmse: 0.225544\n",
      "[9325]\ttraining's rmse: 0.143019\tvalid_1's rmse: 0.225416\n",
      "[9350]\ttraining's rmse: 0.142822\tvalid_1's rmse: 0.225363\n",
      "[9375]\ttraining's rmse: 0.142611\tvalid_1's rmse: 0.225291\n",
      "[9400]\ttraining's rmse: 0.142429\tvalid_1's rmse: 0.225261\n",
      "[9425]\ttraining's rmse: 0.142242\tvalid_1's rmse: 0.225216\n",
      "[9450]\ttraining's rmse: 0.142033\tvalid_1's rmse: 0.225154\n",
      "[9475]\ttraining's rmse: 0.141847\tvalid_1's rmse: 0.225108\n",
      "[9500]\ttraining's rmse: 0.14167\tvalid_1's rmse: 0.225085\n",
      "[9525]\ttraining's rmse: 0.141496\tvalid_1's rmse: 0.225063\n",
      "[9550]\ttraining's rmse: 0.141319\tvalid_1's rmse: 0.225032\n",
      "[9575]\ttraining's rmse: 0.141141\tvalid_1's rmse: 0.225007\n",
      "[9600]\ttraining's rmse: 0.140933\tvalid_1's rmse: 0.224953\n",
      "[9625]\ttraining's rmse: 0.14076\tvalid_1's rmse: 0.224928\n",
      "[9650]\ttraining's rmse: 0.14058\tvalid_1's rmse: 0.224899\n",
      "[9675]\ttraining's rmse: 0.140368\tvalid_1's rmse: 0.224832\n",
      "[9700]\ttraining's rmse: 0.140186\tvalid_1's rmse: 0.224794\n",
      "[9725]\ttraining's rmse: 0.139989\tvalid_1's rmse: 0.224735\n",
      "[9750]\ttraining's rmse: 0.13981\tvalid_1's rmse: 0.224701\n",
      "[9775]\ttraining's rmse: 0.139625\tvalid_1's rmse: 0.224653\n",
      "[9800]\ttraining's rmse: 0.139455\tvalid_1's rmse: 0.224629\n",
      "[9825]\ttraining's rmse: 0.139272\tvalid_1's rmse: 0.224573\n",
      "[9850]\ttraining's rmse: 0.139095\tvalid_1's rmse: 0.224532\n",
      "[9875]\ttraining's rmse: 0.138895\tvalid_1's rmse: 0.224485\n",
      "[9900]\ttraining's rmse: 0.138704\tvalid_1's rmse: 0.224415\n",
      "[9925]\ttraining's rmse: 0.138535\tvalid_1's rmse: 0.224375\n",
      "[9950]\ttraining's rmse: 0.138353\tvalid_1's rmse: 0.224328\n",
      "[9975]\ttraining's rmse: 0.13819\tvalid_1's rmse: 0.224309\n",
      "[10000]\ttraining's rmse: 0.138028\tvalid_1's rmse: 0.22429\n",
      "[10025]\ttraining's rmse: 0.137851\tvalid_1's rmse: 0.224252\n",
      "[10050]\ttraining's rmse: 0.137671\tvalid_1's rmse: 0.224204\n",
      "[10075]\ttraining's rmse: 0.137501\tvalid_1's rmse: 0.224176\n",
      "[10100]\ttraining's rmse: 0.137306\tvalid_1's rmse: 0.224121\n",
      "[10125]\ttraining's rmse: 0.137126\tvalid_1's rmse: 0.224062\n",
      "[10150]\ttraining's rmse: 0.136938\tvalid_1's rmse: 0.224027\n",
      "[10175]\ttraining's rmse: 0.136779\tvalid_1's rmse: 0.224\n",
      "[10200]\ttraining's rmse: 0.136606\tvalid_1's rmse: 0.223956\n",
      "[10225]\ttraining's rmse: 0.136422\tvalid_1's rmse: 0.223914\n",
      "[10250]\ttraining's rmse: 0.136231\tvalid_1's rmse: 0.223854\n",
      "[10275]\ttraining's rmse: 0.136072\tvalid_1's rmse: 0.223829\n",
      "[10300]\ttraining's rmse: 0.135903\tvalid_1's rmse: 0.223801\n",
      "[10325]\ttraining's rmse: 0.135735\tvalid_1's rmse: 0.223767\n",
      "[10350]\ttraining's rmse: 0.135568\tvalid_1's rmse: 0.223723\n",
      "[10375]\ttraining's rmse: 0.135405\tvalid_1's rmse: 0.223702\n",
      "[10400]\ttraining's rmse: 0.135242\tvalid_1's rmse: 0.223659\n",
      "[10425]\ttraining's rmse: 0.135073\tvalid_1's rmse: 0.223611\n",
      "[10450]\ttraining's rmse: 0.134921\tvalid_1's rmse: 0.223589\n",
      "[10475]\ttraining's rmse: 0.134741\tvalid_1's rmse: 0.223547\n",
      "[10500]\ttraining's rmse: 0.134581\tvalid_1's rmse: 0.22353\n",
      "[10525]\ttraining's rmse: 0.134413\tvalid_1's rmse: 0.223499\n",
      "[10550]\ttraining's rmse: 0.134256\tvalid_1's rmse: 0.223476\n",
      "[10575]\ttraining's rmse: 0.134082\tvalid_1's rmse: 0.22342\n",
      "[10600]\ttraining's rmse: 0.133926\tvalid_1's rmse: 0.223417\n",
      "[10625]\ttraining's rmse: 0.133775\tvalid_1's rmse: 0.223393\n",
      "[10650]\ttraining's rmse: 0.133622\tvalid_1's rmse: 0.223366\n",
      "[10675]\ttraining's rmse: 0.133456\tvalid_1's rmse: 0.223324\n",
      "[10700]\ttraining's rmse: 0.133297\tvalid_1's rmse: 0.223296\n",
      "[10725]\ttraining's rmse: 0.133143\tvalid_1's rmse: 0.223278\n",
      "[10750]\ttraining's rmse: 0.13297\tvalid_1's rmse: 0.223229\n",
      "[10775]\ttraining's rmse: 0.132822\tvalid_1's rmse: 0.223202\n",
      "[10800]\ttraining's rmse: 0.13267\tvalid_1's rmse: 0.223176\n",
      "[10825]\ttraining's rmse: 0.132513\tvalid_1's rmse: 0.22315\n",
      "[10850]\ttraining's rmse: 0.132351\tvalid_1's rmse: 0.223123\n",
      "[10875]\ttraining's rmse: 0.132192\tvalid_1's rmse: 0.223095\n",
      "[10900]\ttraining's rmse: 0.132037\tvalid_1's rmse: 0.223069\n",
      "[10925]\ttraining's rmse: 0.131886\tvalid_1's rmse: 0.223037\n",
      "[10950]\ttraining's rmse: 0.131724\tvalid_1's rmse: 0.223003\n",
      "[10975]\ttraining's rmse: 0.13156\tvalid_1's rmse: 0.222969\n",
      "[11000]\ttraining's rmse: 0.131407\tvalid_1's rmse: 0.22294\n",
      "[11025]\ttraining's rmse: 0.131246\tvalid_1's rmse: 0.222907\n",
      "[11050]\ttraining's rmse: 0.131097\tvalid_1's rmse: 0.222893\n",
      "[11075]\ttraining's rmse: 0.13095\tvalid_1's rmse: 0.222869\n",
      "[11100]\ttraining's rmse: 0.130806\tvalid_1's rmse: 0.222852\n",
      "[11125]\ttraining's rmse: 0.130647\tvalid_1's rmse: 0.222817\n",
      "[11150]\ttraining's rmse: 0.130502\tvalid_1's rmse: 0.222801\n",
      "[11175]\ttraining's rmse: 0.130291\tvalid_1's rmse: 0.222708\n",
      "[11200]\ttraining's rmse: 0.130148\tvalid_1's rmse: 0.222686\n",
      "[11225]\ttraining's rmse: 0.129972\tvalid_1's rmse: 0.222618\n",
      "[11250]\ttraining's rmse: 0.129831\tvalid_1's rmse: 0.222606\n",
      "[11275]\ttraining's rmse: 0.12969\tvalid_1's rmse: 0.222585\n",
      "[11300]\ttraining's rmse: 0.129548\tvalid_1's rmse: 0.22256\n",
      "[11325]\ttraining's rmse: 0.129406\tvalid_1's rmse: 0.222544\n",
      "[11350]\ttraining's rmse: 0.129261\tvalid_1's rmse: 0.222507\n",
      "[11375]\ttraining's rmse: 0.129117\tvalid_1's rmse: 0.22249\n",
      "[11400]\ttraining's rmse: 0.128984\tvalid_1's rmse: 0.222466\n",
      "[11425]\ttraining's rmse: 0.128844\tvalid_1's rmse: 0.222456\n",
      "[11450]\ttraining's rmse: 0.128704\tvalid_1's rmse: 0.222443\n",
      "[11475]\ttraining's rmse: 0.128535\tvalid_1's rmse: 0.222398\n",
      "[11500]\ttraining's rmse: 0.128392\tvalid_1's rmse: 0.222378\n",
      "[11525]\ttraining's rmse: 0.128235\tvalid_1's rmse: 0.222336\n",
      "[11550]\ttraining's rmse: 0.128053\tvalid_1's rmse: 0.22226\n",
      "[11575]\ttraining's rmse: 0.127911\tvalid_1's rmse: 0.222237\n",
      "[11600]\ttraining's rmse: 0.127771\tvalid_1's rmse: 0.222224\n",
      "[11625]\ttraining's rmse: 0.127623\tvalid_1's rmse: 0.222184\n",
      "[11650]\ttraining's rmse: 0.127485\tvalid_1's rmse: 0.22216\n",
      "[11675]\ttraining's rmse: 0.127341\tvalid_1's rmse: 0.22214\n",
      "[11700]\ttraining's rmse: 0.127191\tvalid_1's rmse: 0.222118\n",
      "[11725]\ttraining's rmse: 0.127045\tvalid_1's rmse: 0.222092\n",
      "[11750]\ttraining's rmse: 0.126908\tvalid_1's rmse: 0.222087\n",
      "[11775]\ttraining's rmse: 0.126776\tvalid_1's rmse: 0.222062\n",
      "[11800]\ttraining's rmse: 0.126641\tvalid_1's rmse: 0.222052\n",
      "[11825]\ttraining's rmse: 0.126484\tvalid_1's rmse: 0.222005\n",
      "[11850]\ttraining's rmse: 0.126345\tvalid_1's rmse: 0.221982\n",
      "[11875]\ttraining's rmse: 0.126206\tvalid_1's rmse: 0.221956\n",
      "[11900]\ttraining's rmse: 0.126069\tvalid_1's rmse: 0.22193\n",
      "[11925]\ttraining's rmse: 0.125935\tvalid_1's rmse: 0.221922\n",
      "[11950]\ttraining's rmse: 0.125805\tvalid_1's rmse: 0.221914\n",
      "[11975]\ttraining's rmse: 0.125671\tvalid_1's rmse: 0.221904\n",
      "[12000]\ttraining's rmse: 0.125541\tvalid_1's rmse: 0.221898\n",
      "[12025]\ttraining's rmse: 0.125407\tvalid_1's rmse: 0.221874\n",
      "[12050]\ttraining's rmse: 0.125275\tvalid_1's rmse: 0.221857\n",
      "[12075]\ttraining's rmse: 0.125143\tvalid_1's rmse: 0.221847\n",
      "[12100]\ttraining's rmse: 0.125001\tvalid_1's rmse: 0.221815\n",
      "[12125]\ttraining's rmse: 0.124857\tvalid_1's rmse: 0.221779\n",
      "[12150]\ttraining's rmse: 0.124727\tvalid_1's rmse: 0.221764\n",
      "[12175]\ttraining's rmse: 0.124587\tvalid_1's rmse: 0.221733\n",
      "[12200]\ttraining's rmse: 0.124444\tvalid_1's rmse: 0.221716\n",
      "[12225]\ttraining's rmse: 0.124317\tvalid_1's rmse: 0.221695\n",
      "[12250]\ttraining's rmse: 0.12419\tvalid_1's rmse: 0.221684\n",
      "[12275]\ttraining's rmse: 0.124057\tvalid_1's rmse: 0.221672\n",
      "[12300]\ttraining's rmse: 0.123931\tvalid_1's rmse: 0.221656\n",
      "[12325]\ttraining's rmse: 0.123804\tvalid_1's rmse: 0.221633\n",
      "[12350]\ttraining's rmse: 0.123679\tvalid_1's rmse: 0.22161\n",
      "[12375]\ttraining's rmse: 0.12354\tvalid_1's rmse: 0.221576\n",
      "[12400]\ttraining's rmse: 0.123388\tvalid_1's rmse: 0.221523\n",
      "[12425]\ttraining's rmse: 0.123261\tvalid_1's rmse: 0.221507\n",
      "[12450]\ttraining's rmse: 0.123133\tvalid_1's rmse: 0.221491\n",
      "[12475]\ttraining's rmse: 0.123003\tvalid_1's rmse: 0.221466\n",
      "[12500]\ttraining's rmse: 0.122872\tvalid_1's rmse: 0.221439\n",
      "[12525]\ttraining's rmse: 0.122747\tvalid_1's rmse: 0.221413\n",
      "[12550]\ttraining's rmse: 0.122619\tvalid_1's rmse: 0.221395\n",
      "[12575]\ttraining's rmse: 0.122491\tvalid_1's rmse: 0.221387\n",
      "[12600]\ttraining's rmse: 0.122374\tvalid_1's rmse: 0.221378\n",
      "[12625]\ttraining's rmse: 0.122249\tvalid_1's rmse: 0.221359\n",
      "[12650]\ttraining's rmse: 0.122121\tvalid_1's rmse: 0.221341\n",
      "[12675]\ttraining's rmse: 0.121997\tvalid_1's rmse: 0.221326\n",
      "[12700]\ttraining's rmse: 0.121858\tvalid_1's rmse: 0.221301\n",
      "[12725]\ttraining's rmse: 0.121733\tvalid_1's rmse: 0.221275\n",
      "[12750]\ttraining's rmse: 0.121616\tvalid_1's rmse: 0.221268\n",
      "[12775]\ttraining's rmse: 0.121487\tvalid_1's rmse: 0.221243\n",
      "[12800]\ttraining's rmse: 0.121362\tvalid_1's rmse: 0.221235\n",
      "[12825]\ttraining's rmse: 0.121225\tvalid_1's rmse: 0.221194\n",
      "[12850]\ttraining's rmse: 0.121097\tvalid_1's rmse: 0.221164\n",
      "[12875]\ttraining's rmse: 0.120977\tvalid_1's rmse: 0.221158\n",
      "[12900]\ttraining's rmse: 0.120851\tvalid_1's rmse: 0.221137\n",
      "[12925]\ttraining's rmse: 0.120721\tvalid_1's rmse: 0.221119\n",
      "[12950]\ttraining's rmse: 0.120592\tvalid_1's rmse: 0.221094\n",
      "[12975]\ttraining's rmse: 0.120477\tvalid_1's rmse: 0.221084\n",
      "[13000]\ttraining's rmse: 0.120328\tvalid_1's rmse: 0.221046\n",
      "[13025]\ttraining's rmse: 0.120211\tvalid_1's rmse: 0.221027\n",
      "[13050]\ttraining's rmse: 0.120087\tvalid_1's rmse: 0.221004\n",
      "[13075]\ttraining's rmse: 0.119965\tvalid_1's rmse: 0.220988\n",
      "[13100]\ttraining's rmse: 0.119843\tvalid_1's rmse: 0.220973\n",
      "[13125]\ttraining's rmse: 0.119727\tvalid_1's rmse: 0.220953\n",
      "[13150]\ttraining's rmse: 0.119601\tvalid_1's rmse: 0.22094\n",
      "[13175]\ttraining's rmse: 0.119482\tvalid_1's rmse: 0.220926\n",
      "[13200]\ttraining's rmse: 0.119359\tvalid_1's rmse: 0.220915\n",
      "[13225]\ttraining's rmse: 0.119233\tvalid_1's rmse: 0.22089\n",
      "[13250]\ttraining's rmse: 0.119105\tvalid_1's rmse: 0.220865\n",
      "[13275]\ttraining's rmse: 0.118981\tvalid_1's rmse: 0.220853\n",
      "[13300]\ttraining's rmse: 0.118842\tvalid_1's rmse: 0.22081\n",
      "[13325]\ttraining's rmse: 0.118719\tvalid_1's rmse: 0.220781\n",
      "[13350]\ttraining's rmse: 0.118605\tvalid_1's rmse: 0.220774\n",
      "[13375]\ttraining's rmse: 0.118477\tvalid_1's rmse: 0.220732\n",
      "[13400]\ttraining's rmse: 0.118361\tvalid_1's rmse: 0.220714\n",
      "[13425]\ttraining's rmse: 0.118222\tvalid_1's rmse: 0.220676\n",
      "[13450]\ttraining's rmse: 0.1181\tvalid_1's rmse: 0.220659\n",
      "[13475]\ttraining's rmse: 0.117985\tvalid_1's rmse: 0.220646\n",
      "[13500]\ttraining's rmse: 0.117875\tvalid_1's rmse: 0.220636\n",
      "[13525]\ttraining's rmse: 0.117761\tvalid_1's rmse: 0.220631\n",
      "[13550]\ttraining's rmse: 0.117643\tvalid_1's rmse: 0.220613\n",
      "[13575]\ttraining's rmse: 0.117526\tvalid_1's rmse: 0.220599\n",
      "[13600]\ttraining's rmse: 0.117405\tvalid_1's rmse: 0.220582\n",
      "[13625]\ttraining's rmse: 0.117274\tvalid_1's rmse: 0.220561\n",
      "[13650]\ttraining's rmse: 0.117151\tvalid_1's rmse: 0.220543\n",
      "[13675]\ttraining's rmse: 0.117032\tvalid_1's rmse: 0.220518\n",
      "[13700]\ttraining's rmse: 0.116914\tvalid_1's rmse: 0.220496\n",
      "[13725]\ttraining's rmse: 0.116798\tvalid_1's rmse: 0.220475\n",
      "[13750]\ttraining's rmse: 0.11668\tvalid_1's rmse: 0.220454\n",
      "[13775]\ttraining's rmse: 0.116561\tvalid_1's rmse: 0.220432\n",
      "[13800]\ttraining's rmse: 0.11645\tvalid_1's rmse: 0.220422\n",
      "[13825]\ttraining's rmse: 0.116338\tvalid_1's rmse: 0.220417\n",
      "[13850]\ttraining's rmse: 0.116209\tvalid_1's rmse: 0.220387\n",
      "[13875]\ttraining's rmse: 0.116099\tvalid_1's rmse: 0.220372\n",
      "[13900]\ttraining's rmse: 0.115986\tvalid_1's rmse: 0.220359\n",
      "[13925]\ttraining's rmse: 0.115866\tvalid_1's rmse: 0.220346\n",
      "[13950]\ttraining's rmse: 0.115747\tvalid_1's rmse: 0.220319\n",
      "[13975]\ttraining's rmse: 0.115635\tvalid_1's rmse: 0.220314\n",
      "[14000]\ttraining's rmse: 0.115528\tvalid_1's rmse: 0.220302\n",
      "[14025]\ttraining's rmse: 0.115415\tvalid_1's rmse: 0.220293\n",
      "[14050]\ttraining's rmse: 0.115305\tvalid_1's rmse: 0.220286\n",
      "[14075]\ttraining's rmse: 0.115196\tvalid_1's rmse: 0.220277\n",
      "[14100]\ttraining's rmse: 0.115092\tvalid_1's rmse: 0.220268\n",
      "[14125]\ttraining's rmse: 0.114984\tvalid_1's rmse: 0.220267\n",
      "[14150]\ttraining's rmse: 0.11487\tvalid_1's rmse: 0.22025\n",
      "[14175]\ttraining's rmse: 0.114749\tvalid_1's rmse: 0.220223\n",
      "[14200]\ttraining's rmse: 0.114623\tvalid_1's rmse: 0.220185\n",
      "[14225]\ttraining's rmse: 0.114511\tvalid_1's rmse: 0.220166\n",
      "[14250]\ttraining's rmse: 0.114397\tvalid_1's rmse: 0.220143\n",
      "[14275]\ttraining's rmse: 0.114285\tvalid_1's rmse: 0.220119\n",
      "[14300]\ttraining's rmse: 0.114182\tvalid_1's rmse: 0.220116\n",
      "[14325]\ttraining's rmse: 0.11407\tvalid_1's rmse: 0.220099\n",
      "[14350]\ttraining's rmse: 0.113966\tvalid_1's rmse: 0.22009\n",
      "[14375]\ttraining's rmse: 0.113851\tvalid_1's rmse: 0.220058\n",
      "[14400]\ttraining's rmse: 0.113742\tvalid_1's rmse: 0.220038\n",
      "[14425]\ttraining's rmse: 0.11363\tvalid_1's rmse: 0.220025\n",
      "[14450]\ttraining's rmse: 0.113529\tvalid_1's rmse: 0.220009\n",
      "[14475]\ttraining's rmse: 0.113412\tvalid_1's rmse: 0.21999\n",
      "[14500]\ttraining's rmse: 0.113303\tvalid_1's rmse: 0.219973\n",
      "[14525]\ttraining's rmse: 0.113192\tvalid_1's rmse: 0.219947\n",
      "[14550]\ttraining's rmse: 0.113085\tvalid_1's rmse: 0.219929\n",
      "[14575]\ttraining's rmse: 0.112977\tvalid_1's rmse: 0.219914\n",
      "[14600]\ttraining's rmse: 0.112873\tvalid_1's rmse: 0.219915\n",
      "[14625]\ttraining's rmse: 0.112772\tvalid_1's rmse: 0.219912\n",
      "[14650]\ttraining's rmse: 0.112669\tvalid_1's rmse: 0.219904\n",
      "[14675]\ttraining's rmse: 0.112559\tvalid_1's rmse: 0.219887\n",
      "[14700]\ttraining's rmse: 0.112454\tvalid_1's rmse: 0.219868\n",
      "[14725]\ttraining's rmse: 0.112344\tvalid_1's rmse: 0.219854\n",
      "[14750]\ttraining's rmse: 0.112241\tvalid_1's rmse: 0.219839\n",
      "[14775]\ttraining's rmse: 0.112139\tvalid_1's rmse: 0.219834\n",
      "[14800]\ttraining's rmse: 0.112039\tvalid_1's rmse: 0.219824\n",
      "[14825]\ttraining's rmse: 0.111929\tvalid_1's rmse: 0.219807\n",
      "[14850]\ttraining's rmse: 0.111826\tvalid_1's rmse: 0.219808\n",
      "[14875]\ttraining's rmse: 0.111728\tvalid_1's rmse: 0.219798\n",
      "[14900]\ttraining's rmse: 0.111603\tvalid_1's rmse: 0.219767\n",
      "[14925]\ttraining's rmse: 0.111498\tvalid_1's rmse: 0.219757\n",
      "[14950]\ttraining's rmse: 0.111389\tvalid_1's rmse: 0.219742\n",
      "[14975]\ttraining's rmse: 0.11129\tvalid_1's rmse: 0.21973\n",
      "[15000]\ttraining's rmse: 0.111187\tvalid_1's rmse: 0.219722\n",
      "[15025]\ttraining's rmse: 0.111085\tvalid_1's rmse: 0.219719\n",
      "[15050]\ttraining's rmse: 0.110984\tvalid_1's rmse: 0.219713\n",
      "[15075]\ttraining's rmse: 0.110882\tvalid_1's rmse: 0.219701\n",
      "[15100]\ttraining's rmse: 0.110785\tvalid_1's rmse: 0.219685\n",
      "[15125]\ttraining's rmse: 0.110683\tvalid_1's rmse: 0.219667\n",
      "[15150]\ttraining's rmse: 0.110586\tvalid_1's rmse: 0.219662\n",
      "[15175]\ttraining's rmse: 0.110476\tvalid_1's rmse: 0.219653\n",
      "[15200]\ttraining's rmse: 0.110376\tvalid_1's rmse: 0.219649\n",
      "[15225]\ttraining's rmse: 0.110278\tvalid_1's rmse: 0.219636\n",
      "[15250]\ttraining's rmse: 0.110173\tvalid_1's rmse: 0.21961\n",
      "[15275]\ttraining's rmse: 0.110075\tvalid_1's rmse: 0.219596\n",
      "[15300]\ttraining's rmse: 0.109976\tvalid_1's rmse: 0.219584\n",
      "[15325]\ttraining's rmse: 0.109879\tvalid_1's rmse: 0.219571\n",
      "[15350]\ttraining's rmse: 0.10978\tvalid_1's rmse: 0.219551\n",
      "[15375]\ttraining's rmse: 0.109684\tvalid_1's rmse: 0.21954\n",
      "[15400]\ttraining's rmse: 0.109583\tvalid_1's rmse: 0.21953\n",
      "[15425]\ttraining's rmse: 0.109481\tvalid_1's rmse: 0.219519\n",
      "[15450]\ttraining's rmse: 0.109377\tvalid_1's rmse: 0.219502\n",
      "[15475]\ttraining's rmse: 0.109254\tvalid_1's rmse: 0.219467\n",
      "[15500]\ttraining's rmse: 0.109163\tvalid_1's rmse: 0.219453\n",
      "[15525]\ttraining's rmse: 0.109065\tvalid_1's rmse: 0.219434\n",
      "[15550]\ttraining's rmse: 0.108966\tvalid_1's rmse: 0.219428\n",
      "[15575]\ttraining's rmse: 0.108869\tvalid_1's rmse: 0.219418\n",
      "[15600]\ttraining's rmse: 0.108765\tvalid_1's rmse: 0.2194\n",
      "[15625]\ttraining's rmse: 0.108668\tvalid_1's rmse: 0.219387\n",
      "[15650]\ttraining's rmse: 0.108572\tvalid_1's rmse: 0.219377\n",
      "[15675]\ttraining's rmse: 0.108479\tvalid_1's rmse: 0.219376\n",
      "[15700]\ttraining's rmse: 0.108382\tvalid_1's rmse: 0.219363\n",
      "[15725]\ttraining's rmse: 0.108285\tvalid_1's rmse: 0.219353\n",
      "[15750]\ttraining's rmse: 0.108175\tvalid_1's rmse: 0.219325\n",
      "[15775]\ttraining's rmse: 0.108082\tvalid_1's rmse: 0.219318\n",
      "[15800]\ttraining's rmse: 0.107989\tvalid_1's rmse: 0.219312\n",
      "[15825]\ttraining's rmse: 0.107891\tvalid_1's rmse: 0.219289\n",
      "[15850]\ttraining's rmse: 0.107789\tvalid_1's rmse: 0.219272\n",
      "[15875]\ttraining's rmse: 0.107692\tvalid_1's rmse: 0.219257\n",
      "[15900]\ttraining's rmse: 0.107599\tvalid_1's rmse: 0.219241\n",
      "[15925]\ttraining's rmse: 0.107501\tvalid_1's rmse: 0.219221\n",
      "[15950]\ttraining's rmse: 0.107399\tvalid_1's rmse: 0.21921\n",
      "[15975]\ttraining's rmse: 0.107304\tvalid_1's rmse: 0.219205\n",
      "[16000]\ttraining's rmse: 0.107213\tvalid_1's rmse: 0.219194\n",
      "[16025]\ttraining's rmse: 0.107125\tvalid_1's rmse: 0.219188\n",
      "[16050]\ttraining's rmse: 0.107031\tvalid_1's rmse: 0.219175\n",
      "[16075]\ttraining's rmse: 0.106931\tvalid_1's rmse: 0.219169\n",
      "[16100]\ttraining's rmse: 0.10684\tvalid_1's rmse: 0.21917\n",
      "[16125]\ttraining's rmse: 0.106748\tvalid_1's rmse: 0.219163\n",
      "[16150]\ttraining's rmse: 0.106655\tvalid_1's rmse: 0.21915\n",
      "[16175]\ttraining's rmse: 0.106564\tvalid_1's rmse: 0.219143\n",
      "[16200]\ttraining's rmse: 0.10647\tvalid_1's rmse: 0.219134\n",
      "[16225]\ttraining's rmse: 0.10638\tvalid_1's rmse: 0.21912\n",
      "[16250]\ttraining's rmse: 0.106286\tvalid_1's rmse: 0.219103\n",
      "[16275]\ttraining's rmse: 0.106194\tvalid_1's rmse: 0.219097\n",
      "[16300]\ttraining's rmse: 0.1061\tvalid_1's rmse: 0.219084\n",
      "[16325]\ttraining's rmse: 0.106008\tvalid_1's rmse: 0.219074\n",
      "[16350]\ttraining's rmse: 0.105912\tvalid_1's rmse: 0.219055\n",
      "[16375]\ttraining's rmse: 0.105823\tvalid_1's rmse: 0.219043\n",
      "[16400]\ttraining's rmse: 0.105729\tvalid_1's rmse: 0.219028\n",
      "[16425]\ttraining's rmse: 0.105638\tvalid_1's rmse: 0.219025\n",
      "[16450]\ttraining's rmse: 0.105548\tvalid_1's rmse: 0.21901\n",
      "[16475]\ttraining's rmse: 0.105461\tvalid_1's rmse: 0.219001\n",
      "[16500]\ttraining's rmse: 0.105374\tvalid_1's rmse: 0.218984\n",
      "[16525]\ttraining's rmse: 0.105283\tvalid_1's rmse: 0.218986\n",
      "[16550]\ttraining's rmse: 0.105192\tvalid_1's rmse: 0.218977\n",
      "[16575]\ttraining's rmse: 0.105103\tvalid_1's rmse: 0.218973\n",
      "[16600]\ttraining's rmse: 0.105004\tvalid_1's rmse: 0.218964\n",
      "[16625]\ttraining's rmse: 0.104918\tvalid_1's rmse: 0.218945\n",
      "[16650]\ttraining's rmse: 0.104832\tvalid_1's rmse: 0.218949\n",
      "[16675]\ttraining's rmse: 0.104743\tvalid_1's rmse: 0.218931\n",
      "[16700]\ttraining's rmse: 0.104653\tvalid_1's rmse: 0.218937\n",
      "[16725]\ttraining's rmse: 0.10456\tvalid_1's rmse: 0.21893\n",
      "[16750]\ttraining's rmse: 0.104465\tvalid_1's rmse: 0.218907\n",
      "[16775]\ttraining's rmse: 0.104371\tvalid_1's rmse: 0.218895\n",
      "[16800]\ttraining's rmse: 0.104285\tvalid_1's rmse: 0.218888\n",
      "[16825]\ttraining's rmse: 0.104194\tvalid_1's rmse: 0.218878\n",
      "[16850]\ttraining's rmse: 0.104101\tvalid_1's rmse: 0.218864\n",
      "[16875]\ttraining's rmse: 0.104011\tvalid_1's rmse: 0.218858\n",
      "[16900]\ttraining's rmse: 0.103923\tvalid_1's rmse: 0.218851\n",
      "[16925]\ttraining's rmse: 0.103838\tvalid_1's rmse: 0.218846\n",
      "[16950]\ttraining's rmse: 0.103751\tvalid_1's rmse: 0.218831\n",
      "[16975]\ttraining's rmse: 0.10366\tvalid_1's rmse: 0.218808\n",
      "[17000]\ttraining's rmse: 0.103562\tvalid_1's rmse: 0.218782\n",
      "[17025]\ttraining's rmse: 0.103471\tvalid_1's rmse: 0.21878\n",
      "[17050]\ttraining's rmse: 0.103381\tvalid_1's rmse: 0.218775\n",
      "[17075]\ttraining's rmse: 0.103294\tvalid_1's rmse: 0.218769\n",
      "[17100]\ttraining's rmse: 0.103206\tvalid_1's rmse: 0.218761\n",
      "[17125]\ttraining's rmse: 0.103121\tvalid_1's rmse: 0.218758\n",
      "[17150]\ttraining's rmse: 0.103037\tvalid_1's rmse: 0.218754\n",
      "[17175]\ttraining's rmse: 0.102952\tvalid_1's rmse: 0.21874\n",
      "[17200]\ttraining's rmse: 0.10286\tvalid_1's rmse: 0.218722\n",
      "[17225]\ttraining's rmse: 0.102775\tvalid_1's rmse: 0.218711\n",
      "[17250]\ttraining's rmse: 0.10269\tvalid_1's rmse: 0.218704\n",
      "[17275]\ttraining's rmse: 0.102609\tvalid_1's rmse: 0.218693\n",
      "[17300]\ttraining's rmse: 0.102525\tvalid_1's rmse: 0.218691\n",
      "[17325]\ttraining's rmse: 0.102438\tvalid_1's rmse: 0.218673\n",
      "[17350]\ttraining's rmse: 0.102357\tvalid_1's rmse: 0.218664\n",
      "[17375]\ttraining's rmse: 0.102276\tvalid_1's rmse: 0.218648\n",
      "[17400]\ttraining's rmse: 0.102187\tvalid_1's rmse: 0.218637\n",
      "[17425]\ttraining's rmse: 0.102104\tvalid_1's rmse: 0.218627\n",
      "[17450]\ttraining's rmse: 0.102017\tvalid_1's rmse: 0.21862\n",
      "[17475]\ttraining's rmse: 0.101934\tvalid_1's rmse: 0.218614\n",
      "[17500]\ttraining's rmse: 0.101852\tvalid_1's rmse: 0.218611\n",
      "[17525]\ttraining's rmse: 0.101766\tvalid_1's rmse: 0.218603\n",
      "[17550]\ttraining's rmse: 0.101684\tvalid_1's rmse: 0.218597\n",
      "[17575]\ttraining's rmse: 0.101603\tvalid_1's rmse: 0.218594\n",
      "[17600]\ttraining's rmse: 0.101514\tvalid_1's rmse: 0.21858\n",
      "[17625]\ttraining's rmse: 0.10143\tvalid_1's rmse: 0.218577\n",
      "[17650]\ttraining's rmse: 0.101339\tvalid_1's rmse: 0.218561\n",
      "[17675]\ttraining's rmse: 0.101252\tvalid_1's rmse: 0.218554\n",
      "[17700]\ttraining's rmse: 0.101173\tvalid_1's rmse: 0.218546\n",
      "[17725]\ttraining's rmse: 0.10109\tvalid_1's rmse: 0.218534\n",
      "[17750]\ttraining's rmse: 0.10101\tvalid_1's rmse: 0.218523\n",
      "[17775]\ttraining's rmse: 0.100926\tvalid_1's rmse: 0.218508\n",
      "[17800]\ttraining's rmse: 0.100847\tvalid_1's rmse: 0.218502\n",
      "[17825]\ttraining's rmse: 0.100765\tvalid_1's rmse: 0.218494\n",
      "[17850]\ttraining's rmse: 0.10068\tvalid_1's rmse: 0.218488\n",
      "[17875]\ttraining's rmse: 0.1006\tvalid_1's rmse: 0.21849\n",
      "[17900]\ttraining's rmse: 0.10052\tvalid_1's rmse: 0.218488\n",
      "[17925]\ttraining's rmse: 0.100439\tvalid_1's rmse: 0.218482\n",
      "[17950]\ttraining's rmse: 0.100361\tvalid_1's rmse: 0.218486\n",
      "[17975]\ttraining's rmse: 0.100285\tvalid_1's rmse: 0.218478\n",
      "[18000]\ttraining's rmse: 0.100205\tvalid_1's rmse: 0.218478\n",
      "[18025]\ttraining's rmse: 0.100121\tvalid_1's rmse: 0.218467\n",
      "[18050]\ttraining's rmse: 0.100043\tvalid_1's rmse: 0.218473\n",
      "[18075]\ttraining's rmse: 0.0999649\tvalid_1's rmse: 0.218463\n",
      "[18100]\ttraining's rmse: 0.0998864\tvalid_1's rmse: 0.218463\n",
      "[18125]\ttraining's rmse: 0.0998051\tvalid_1's rmse: 0.218452\n",
      "[18150]\ttraining's rmse: 0.0997248\tvalid_1's rmse: 0.218443\n",
      "[18175]\ttraining's rmse: 0.0996492\tvalid_1's rmse: 0.21844\n",
      "[18200]\ttraining's rmse: 0.0995704\tvalid_1's rmse: 0.218432\n",
      "[18225]\ttraining's rmse: 0.099489\tvalid_1's rmse: 0.218424\n",
      "[18250]\ttraining's rmse: 0.0994083\tvalid_1's rmse: 0.218416\n",
      "[18275]\ttraining's rmse: 0.0993306\tvalid_1's rmse: 0.218415\n",
      "[18300]\ttraining's rmse: 0.0992517\tvalid_1's rmse: 0.218403\n",
      "[18325]\ttraining's rmse: 0.0991735\tvalid_1's rmse: 0.218397\n",
      "[18350]\ttraining's rmse: 0.0991017\tvalid_1's rmse: 0.218395\n",
      "[18375]\ttraining's rmse: 0.0990247\tvalid_1's rmse: 0.218398\n",
      "[18400]\ttraining's rmse: 0.0989426\tvalid_1's rmse: 0.218388\n",
      "[18425]\ttraining's rmse: 0.0988637\tvalid_1's rmse: 0.218381\n",
      "[18450]\ttraining's rmse: 0.098788\tvalid_1's rmse: 0.218373\n",
      "[18475]\ttraining's rmse: 0.0987127\tvalid_1's rmse: 0.218373\n",
      "[18500]\ttraining's rmse: 0.0986339\tvalid_1's rmse: 0.218363\n",
      "[18525]\ttraining's rmse: 0.0985546\tvalid_1's rmse: 0.218354\n",
      "[18550]\ttraining's rmse: 0.0984721\tvalid_1's rmse: 0.218344\n",
      "[18575]\ttraining's rmse: 0.0983942\tvalid_1's rmse: 0.218333\n",
      "[18600]\ttraining's rmse: 0.0983177\tvalid_1's rmse: 0.218323\n",
      "[18625]\ttraining's rmse: 0.0982387\tvalid_1's rmse: 0.218323\n",
      "[18650]\ttraining's rmse: 0.0981617\tvalid_1's rmse: 0.218317\n",
      "[18675]\ttraining's rmse: 0.0980808\tvalid_1's rmse: 0.218301\n",
      "[18700]\ttraining's rmse: 0.0980039\tvalid_1's rmse: 0.218291\n",
      "[18725]\ttraining's rmse: 0.0979249\tvalid_1's rmse: 0.218286\n",
      "[18750]\ttraining's rmse: 0.0978488\tvalid_1's rmse: 0.218284\n",
      "[18775]\ttraining's rmse: 0.097773\tvalid_1's rmse: 0.218278\n",
      "[18800]\ttraining's rmse: 0.0976968\tvalid_1's rmse: 0.218272\n",
      "[18825]\ttraining's rmse: 0.0976254\tvalid_1's rmse: 0.218264\n",
      "[18850]\ttraining's rmse: 0.0975495\tvalid_1's rmse: 0.218255\n",
      "[18875]\ttraining's rmse: 0.0974744\tvalid_1's rmse: 0.218249\n",
      "[18900]\ttraining's rmse: 0.0973983\tvalid_1's rmse: 0.218241\n",
      "[18925]\ttraining's rmse: 0.0973214\tvalid_1's rmse: 0.218231\n",
      "[18950]\ttraining's rmse: 0.097245\tvalid_1's rmse: 0.218226\n",
      "[18975]\ttraining's rmse: 0.0971724\tvalid_1's rmse: 0.218225\n",
      "[19000]\ttraining's rmse: 0.0970977\tvalid_1's rmse: 0.218224\n",
      "[19025]\ttraining's rmse: 0.0970245\tvalid_1's rmse: 0.218222\n",
      "[19050]\ttraining's rmse: 0.0969498\tvalid_1's rmse: 0.218214\n",
      "[19075]\ttraining's rmse: 0.096875\tvalid_1's rmse: 0.218216\n",
      "[19100]\ttraining's rmse: 0.0967982\tvalid_1's rmse: 0.218212\n",
      "[19125]\ttraining's rmse: 0.0967259\tvalid_1's rmse: 0.218206\n",
      "[19150]\ttraining's rmse: 0.0966474\tvalid_1's rmse: 0.218203\n",
      "[19175]\ttraining's rmse: 0.0965742\tvalid_1's rmse: 0.218199\n",
      "[19200]\ttraining's rmse: 0.0964996\tvalid_1's rmse: 0.218195\n",
      "[19225]\ttraining's rmse: 0.0964263\tvalid_1's rmse: 0.218188\n",
      "[19250]\ttraining's rmse: 0.0963509\tvalid_1's rmse: 0.218181\n",
      "[19275]\ttraining's rmse: 0.0962794\tvalid_1's rmse: 0.218181\n",
      "[19300]\ttraining's rmse: 0.0962042\tvalid_1's rmse: 0.218169\n",
      "[19325]\ttraining's rmse: 0.0961275\tvalid_1's rmse: 0.218158\n",
      "[19350]\ttraining's rmse: 0.0960546\tvalid_1's rmse: 0.218151\n",
      "[19375]\ttraining's rmse: 0.0959832\tvalid_1's rmse: 0.218148\n",
      "[19400]\ttraining's rmse: 0.0959135\tvalid_1's rmse: 0.218143\n",
      "[19425]\ttraining's rmse: 0.095841\tvalid_1's rmse: 0.218141\n",
      "[19450]\ttraining's rmse: 0.0957664\tvalid_1's rmse: 0.218144\n",
      "Early stopping, best iteration is:\n",
      "[19408]\ttraining's rmse: 0.0958894\tvalid_1's rmse: 0.218139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) Train-test split and model training with early stopping\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'bagging_fraction': 0.6307598531013435,\n",
    "    'feature_fraction': 0.9100021508065013,\n",
    "    'lambda_l1': 9.794332222263648,\n",
    "    'lambda_l2': 1.5125116822949636,\n",
    "    'min_child_samples': 76,\n",
    "    'min_child_weight': 6.517089323249935,\n",
    "    'num_leaves': 92,\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.25457289118658527,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "\n",
    "model = lgb.train(params, lgb_train, num_boost_round=20000,\n",
    "                  valid_sets=[lgb_train, lgb_val],\n",
    "                  callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=25)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09cbcfc-6e01-459e-aa31-e0bdcc79824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.047584439894809344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6) Predict and evaluate\n",
    "val_preds = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, val_preds)\n",
    "print(\"Validation RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02fe266f-5562-4add-8b14-c9a6261ba37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 7) SHAP explainability\\nexplainer = shap.Explainer(model, X)\\nshap_values = explainer(X)\\nshap.summary_plot(shap_values, X)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 7) SHAP explainability\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "shap.summary_plot(shap_values, X)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e81ea06-e209-4728-b94a-bfbb58db7a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique ID  Lap_Time_Seconds\n",
      "0     288307         90.378858\n",
      "1     704288        104.147832\n",
      "2     951491         86.339750\n",
      "3    2591721        109.712509\n",
      "4    1202653         99.216205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8) Predict on test set and create output\n",
    "preds = model.predict(X_test)\n",
    "out = pd.DataFrame({\n",
    "    'Unique ID': test['Unique ID'],\n",
    "    'Lap_Time_Seconds': preds\n",
    "})\n",
    "\n",
    "out.to_csv(\"LGBMsolution.csv\", index=False)\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44fb5cf-aa5a-4fc8-975f-1b55a6f22895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04861d-ead5-4463-bdc7-a775cb0bad14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
